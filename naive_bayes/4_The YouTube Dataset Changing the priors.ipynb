{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e8a08de",
   "metadata": {},
   "source": [
    "# Exercise - 20 Newsgroups Dataset - Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e12d05",
   "metadata": {},
   "source": [
    "### Introducing a solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd335f5",
   "metadata": {},
   "source": [
    "**In this notebook, we only give guidelines on how the problem can be solved. You can use it to resolve an error you might have encountered or just for inspiration. The notebook does not necessarily present the best solution.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03be8c8",
   "metadata": {},
   "source": [
    "### Introducing the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db9fe0d",
   "metadata": {},
   "source": [
    "In this assignment, you will be introduced to the **20 newsgroups text dataset**. It is one of the real-world datasets that can be directly imported from sklearn. The dataset consists of 18000 newsgroup posts on 20 topics.\n",
    "\n",
    "The code under the following sections is implemented:\n",
    "* **Importing the necessary libraries** - **some** of the libraries necessary for the next section are imported. The rest we leave for you to import.\n",
    "* **Reading the database** - in this section, we do the following:\n",
    "    - fetch the 20 newsgroups dataset\n",
    "    - display the type of the **newsgroups** variable\n",
    "    - display the names of all classes\n",
    "    - display the first post in the database just to have an idea of how the dataset looks like\n",
    "    - display the targets\n",
    "    - using the Counter class, count the number of times each target has occurred in the list of targets\n",
    "    \n",
    "Your task is to build a Naive Bayes model in a similar fashion to the spam-filtering model we have built during the course. Then, analyze your results with the help of a confusion matrix and a classification report. Test both the multinomial and the complement naive bayes classifiers.\n",
    "\n",
    "*Hint: Make use of the **categories** variable to print out the classification report.*\n",
    "\n",
    "Good luck and have fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3e5f86",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21a29390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa95f42",
   "metadata": {},
   "source": [
    "### Reading the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "528b4978",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dce12216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(newsgroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a42aa005",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = newsgroups.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8a9447f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "075b87a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 4, 4, ..., 3, 1, 8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61231e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({7: 594,\n",
       "         4: 578,\n",
       "         1: 584,\n",
       "         14: 593,\n",
       "         16: 546,\n",
       "         13: 594,\n",
       "         3: 590,\n",
       "         2: 591,\n",
       "         8: 598,\n",
       "         19: 377,\n",
       "         6: 585,\n",
       "         0: 480,\n",
       "         12: 591,\n",
       "         5: 593,\n",
       "         10: 600,\n",
       "         9: 597,\n",
       "         15: 599,\n",
       "         17: 564,\n",
       "         18: 465,\n",
       "         11: 595})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(newsgroups.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8108d584",
   "metadata": {},
   "source": [
    "### Defining the inputs and the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e22f6956",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = newsgroups.data\n",
    "target = newsgroups.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "071bdc34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd68ef4",
   "metadata": {},
   "source": [
    "### Creating the train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81023af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(inputs, target, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=365, \n",
    "                                                    stratify = target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4878d1",
   "metadata": {},
   "source": [
    "### Tokenizing the YouTube comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38eba10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "x_train_transf = vectorizer.fit_transform(x_train)\n",
    "x_test_transf = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4a8c7f",
   "metadata": {},
   "source": [
    "### Performing the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f88adaab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "\n",
    "clf.fit(x_train_transf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0d523f",
   "metadata": {},
   "source": [
    "### Performing the evaluation on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f3faf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = clf.predict(x_test_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "644059d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 81   0   0   0   0   0   0   0   0   0   0   0   0   0   0  13   0   1\n",
      "    0   1]\n",
      " [  0  94   0   6   0  12   0   0   0   0   0   2   0   0   0   1   0   0\n",
      "    2   0]\n",
      " [  0  21   5  36   5  39   1   1   0   0   0   5   2   1   0   1   1   0\n",
      "    0   0]\n",
      " [  0   8   0  96   2   2   1   0   0   0   0   1   3   1   2   0   0   1\n",
      "    1   0]\n",
      " [  0   2   0   5  98   1   1   0   0   0   0   1   3   2   0   0   0   1\n",
      "    1   0]\n",
      " [  0   2   0   0   0 116   0   0   0   0   0   0   0   1   0   0   0   0\n",
      "    0   0]\n",
      " [  0   3   0   5   3   2  73   8   0   0   0   1   9   2   1   0   2   5\n",
      "    3   0]\n",
      " [  0   0   0   0   0   1   2 109   1   0   0   1   0   0   0   1   2   1\n",
      "    1   0]\n",
      " [  0   1   0   0   0   1   1   1 108   0   0   0   0   0   0   1   2   3\n",
      "    2   0]\n",
      " [  0   0   0   0   0   1   0   0   0 109   3   0   0   0   1   1   1   1\n",
      "    2   0]\n",
      " [  0   1   0   0   0   1   0   1   0   0 114   0   0   0   0   1   0   0\n",
      "    2   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 117   0   0   0   0   0   1\n",
      "    1   0]\n",
      " [  0   3   0   4   3   2   1   2   0   0   0   1  95   1   4   0   1   1\n",
      "    0   0]\n",
      " [  0   0   0   0   0   1   0   0   0   1   0   0   1 110   1   0   2   2\n",
      "    1   0]\n",
      " [  0   3   0   0   0   0   0   0   0   0   0   0   1   1 113   0   0   0\n",
      "    1   0]\n",
      " [  1   0   0   0   1   0   0   0   0   0   0   1   0   0   0 114   0   2\n",
      "    1   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0   0   1   0   0   0   0 103   1\n",
      "    3   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0 111\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   1   0   1   0   3   0   0   0   1   1   0\n",
      "   86   0]\n",
      " [  8   0   0   0   0   0   0   0   0   0   0   0   0   0   1  24   3   3\n",
      "    1  35]]\n"
     ]
    }
   ],
   "source": [
    "sns.reset_orig()\n",
    "\n",
    "#ConfusionMatrixDisplay.from_predictions(\n",
    "  #  y_test, y_test_pred,\n",
    "  #  labels = clf.classes_,\n",
    "#   cmap = 'magma'\n",
    "#);\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98296cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.89      0.84      0.87        96\n",
      "           comp.graphics       0.68      0.80      0.74       117\n",
      " comp.os.ms-windows.misc       1.00      0.04      0.08       118\n",
      "comp.sys.ibm.pc.hardware       0.63      0.81      0.71       118\n",
      "   comp.sys.mac.hardware       0.88      0.85      0.86       115\n",
      "          comp.windows.x       0.65      0.97      0.78       119\n",
      "            misc.forsale       0.91      0.62      0.74       117\n",
      "               rec.autos       0.89      0.92      0.90       119\n",
      "         rec.motorcycles       0.98      0.90      0.94       120\n",
      "      rec.sport.baseball       0.98      0.92      0.95       119\n",
      "        rec.sport.hockey       0.97      0.95      0.96       120\n",
      "               sci.crypt       0.87      0.98      0.92       119\n",
      "         sci.electronics       0.83      0.81      0.82       118\n",
      "                 sci.med       0.92      0.92      0.92       119\n",
      "               sci.space       0.92      0.95      0.93       119\n",
      "  soc.religion.christian       0.72      0.95      0.82       120\n",
      "      talk.politics.guns       0.87      0.94      0.91       109\n",
      "   talk.politics.mideast       0.83      0.98      0.90       113\n",
      "      talk.politics.misc       0.80      0.92      0.86        93\n",
      "      talk.religion.misc       0.97      0.47      0.63        75\n",
      "\n",
      "                accuracy                           0.83      2263\n",
      "               macro avg       0.86      0.83      0.81      2263\n",
      "            weighted avg       0.86      0.83      0.81      2263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_test_pred, target_names = categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd68b685",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
